{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parse a single file\n",
    "def parse_file(filename):\n",
    "    \n",
    "    # Grab and open the file\n",
    "    handle = open(filename, 'rb')\n",
    "    soup = BeautifulSoup(handle, \"lxml\")\n",
    "\n",
    "    # Create the article object to hold the parsed information\n",
    "    article = {}\n",
    "\n",
    "    #\n",
    "    # Header Information\n",
    "    #\n",
    "\n",
    "    # Parse the title\n",
    "    if (soup.teiheader.filedesc.titlestmt.title != None):\n",
    "        article[\"title\"] = soup.teiheader.filedesc.titlestmt.title.getText()\n",
    "\n",
    "    article[\"properties\"] = {}\n",
    "    article[\"properties\"][\"type\"] = \"article\"\n",
    "\n",
    "    # Parse the publisher information\n",
    "    if (soup.teiheader.filedesc.publicationstmt != None):\n",
    "        article[\"properties\"][\"publisher\"] = {}\n",
    "        publisher = soup.teiheader.filedesc.publicationstmt.findChildren(recursive=False)\n",
    "        for item in publisher:\n",
    "            article[\"properties\"][\"publisher\"][item.name] = item.getText()\n",
    "\n",
    "    #   \n",
    "    # Grab the Authors section\n",
    "    #\n",
    "    authorsInput = soup.teiheader.filedesc.sourcedesc.findAll('author')\n",
    "    article[\"properties\"][\"authors\"] = []\n",
    "\n",
    "    # Then Parse through it\n",
    "    for item in authorsInput:\n",
    "        author = {}\n",
    "\n",
    "        # Names\n",
    "        author['name'] = {}\n",
    "\n",
    "        # Forenames\n",
    "        for name in item.persname.findAll('forename'):\n",
    "            author[\"name\"][name['type']] = name.getText()\n",
    "\n",
    "        # Surname\n",
    "        if(item.persname.surname != None):\n",
    "            author[\"name\"][\"surname\"] = item.persname.surname.getText()\n",
    "\n",
    "        # Rolename?\n",
    "        if(item.persname.rolename != None):\n",
    "            author[\"name\"][\"rolename\"] = item.persname.rolename.getText()\n",
    "\n",
    "        # Affiliations\n",
    "        if(item.affiliation != None):\n",
    "            author['affiliation'] = {}\n",
    "\n",
    "            # Affiliation components\n",
    "            for name in item.affiliation.findAll('orgname'):\n",
    "                author[\"affiliation\"][name['type']] = name.getText()\n",
    "\n",
    "            # Address of org\n",
    "            if(item.affiliation.address != None):\n",
    "                author['affiliation'][\"address\"] = {}\n",
    "                for addressComponent in item.affiliation.address.findAll():\n",
    "                    author['affiliation'][\"address\"][addressComponent.name] = addressComponent.getText()\n",
    "\n",
    "        # Save the author\n",
    "        article[\"properties\"][\"authors\"].append(author)\n",
    "\n",
    "    #  \n",
    "    # Grab journal Information\n",
    "    #\n",
    "    if(soup.teiheader.filedesc.sourcedesc.monogr != None):\n",
    "        article[\"properties\"][\"journal\"] = {}\n",
    "        if (soup.teiheader.filedesc.sourcedesc.monogr.title != None):\n",
    "            article[\"properties\"][\"journal\"][\"title\"] = soup.teiheader.filedesc.sourcedesc.monogr.title.getText()\n",
    "\n",
    "        # Grab journal publisher information\n",
    "        if (soup.teiheader.filedesc.sourcedesc.monogr.imprint != None):            \n",
    "            # This bit if a bit brittle... stupid format...\n",
    "            for item in soup.teiheader.filedesc.sourcedesc.monogr.imprint.findChildren():\n",
    "\n",
    "                #Publisher\n",
    "                if(item.name == \"publisher\"):\n",
    "                    article[\"properties\"][\"journal\"][\"publisher\"] = soup.teiheader.filedesc.sourcedesc.monogr.imprint.publisher.getText()\n",
    "\n",
    "                # Parse Date\n",
    "                elif (item.name == \"date\"):\n",
    "                    article[\"properties\"][\"journal\"][item['type']] = item.getText()\n",
    "\n",
    "                # Journal bibliographic information\n",
    "                elif (item.name == \"biblscope\"):\n",
    "                    # Page\n",
    "                    if(item['unit'] == \"page\"):\n",
    "                        article[\"properties\"][\"journal\"][\"page\"] = {}\n",
    "                        if(item['from'] != None):\n",
    "                            article[\"properties\"][\"journal\"][\"page\"][\"from\"] = item['from']\n",
    "                        if(item['from'] != None):\n",
    "                            article[\"properties\"][\"journal\"][\"page\"][\"to\"] = item['to']\n",
    "                    # Volume\n",
    "                    elif(item['unit'] == \"volume\"):\n",
    "                        article[\"properties\"][\"journal\"][\"volume\"] = item.getText()\n",
    "                # Print out other possibilities to prompt inclusion when encountered\n",
    "                else:\n",
    "                    print(item, \"1\")\n",
    "\n",
    "    #Grab The DOI\n",
    "    if(soup.teiheader.filedesc.sourcedesc.idno != None):\n",
    "        if(soup.teiheader.filedesc.sourcedesc.idno[\"type\"] == \"DOI\"):\n",
    "            article[\"properties\"][\"doi\"] = soup.teiheader.filedesc.sourcedesc.idno.getText()  \n",
    "\n",
    "    #\n",
    "    # Parse through the sections\n",
    "    #\n",
    "    article[\"sections\"] = []\n",
    "\n",
    "    # Parse the abstract should it exist\n",
    "    if(soup.teiheader.profiledesc.abstract != None):\n",
    "        article[\"sections\"].append({\"title\": \"Abstract\", \"type\": \"abstract\", \"number\": 0, \"paragraphs\": [soup.teiheader.profiledesc.abstract.getText()], \"references\": []})\n",
    "\n",
    "\n",
    "    # Parase the body\n",
    "\n",
    "    for div in soup.tei.find('text').findAll('div'):\n",
    "        section = {}\n",
    "\n",
    "        # The line below is super brittle, soup can't find the head tags defined in the TEI xml\n",
    "        section['title'] = div.get_text().split('\\n')[1].split('\\t')[-1]\n",
    "        section[\"paragraphs\"] = []\n",
    "        for p in div.findAll('p'):\n",
    "            section[\"paragraphs\"].append(p.getText())\n",
    "\n",
    "        article[\"sections\"].append(section)\n",
    "\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sections': [{'references': [], 'paragraphs': [u'\\nA primary research stream that contributed to the birth of case-based reasoning (CBR) was Artificial Intelligence and Law. Since law is largely about cases, it is a particularly interesting domain for CBR researchers. This article surveys some of the historically significant systems and developments in this field.\\n'], 'type': 'abstract', 'number': 0, 'title': 'Abstract'}, {'paragraphs': [u\"Significantly for CBR, reasoning with hypotheticals in law is related to reasoning with examples in other domains like mathematics and to adapting exemplars to solve problems. In her doctoral research, Rissland created a model of mathematical knowledge and understanding that gave a prominent role to concrete and prototype examples and their interconnections\\u2014so-called Examples-space\\u2014in the network of mathematical knowledge (Rissland, 1977, 1978). In the early 1980s, she studied how one generates examples that satisfy certain desiderata for use, for instance, in teaching and doing mathematics. Constrained Example Generation (CEG) worked by retrieving a good example (e.g., one maximizing the number of constraints satisfied) and then modifying it to try to satisfy additional constraints (Rissland, 1980; Rissland & Soloway, 1980). CEG's 'retrieval-plus-modification' architecture made it an early forerunner of adaptive CBR systems.\", u\"Initially concerned with how legal experts create hypos, Rissland and Ashley (then her student) embarked on a research program that led to the landmark HYPO system (Rissland et al, 1984; Rissland & Ashley, 1987; Ashley & Rissland, 1988). HYPO was brought to fruition in Ashley's doctoral research (Ashley, 1988, 1990). HYPO was the first true CBR system in the legal domain.\", u\"While there had been earlier legal reasoning systems (e.g., Gardner, 1987) that used examples, HYPO was the first to use cases, that is, actual precedents. HYPO's initial focus was on the creation of legal hypotheticals\\u2014hence its name\\u2014by generating a hypothetical case based on an existing case and modifying it according to a particular way of looking at the problem, for instance to make it more extreme (Rissland & Ashley, 1986). Modifications were guided by knowledge captured in dimensions, one of the key innovations of HYPO, an idea first introduced in a 1984 AAAI paper (Rissland et al., 1984; Ashley, 1988, 1990; Rissland & Ashley, 2002).\"], 'title': u'Examples, hypos, and HYPO'}, {'paragraphs': [u\"HYPO, a paradigm interpretive CBR system, performs the entire sequence of steps of CBR from analysis to argumentation: it analyzes a new case; retrieves relevant cases from its case base; sorts them according to how on-point they are (in a 'claim lattice'); selects best cases for each side of the issue; generates '3-ply' point\\u2013counterpoint\\u2013rebuttal style arguments; and explores strengths and weaknesses of each side's arguments using hypotheticals (Ashley, 1988, 1989, 1990, 1991). Among HYPO's novel contributions are its definitions of relevance and on-pointness and its methods to compare and contrast cases in terms of dimensions. Dimensions capture the knowledge that certain frequently occurring fact patterns enable one to approach a legal dispute in a particular way and that certain changes in these facts tend to strengthen or weaken a side's claim. For instance, in trade secrets law (HYPO's domain), one way to approach a misappropriation claim is to focus on the number of disclosures the plaintiff made of its putative trade secret. Ceteris paribus, the more disclosures there are, the weaker the argument for a misappropriation, or equivalently, the stronger the argument that the defendant is blameless. The plaintiff's position is strongest where it made no disclosures, far weaker where there were many disclosures. This is the basis of HYPO's 'Secrets-Voluntarily-Disclosed' dimension (Ashley, 1988, 1990). HYPO has had many progeny, including CABARET, BankXX, SPIRE, CATO, SMILE, and IBP. Central to each of these is a HYPO-style analysis. CATO harnessed HYPO's model of legal argument to teach law students how to make arguments with cases (Aleven, 1997, 2003; Aleven & Ashley, 1997). For instance, if CATO noticed that a student has not distinguished an opponent's case in the most effective way possible or has cited a case that can be trumped by an opponent's more on-point case, CATO generated the opponent's arguments to explain the student's mistakes. In the CATO system, Ashley and his student Aleven addressed the fact that dimensions are often related to each other and to higher-level legal reasons. They introduced factors, a construct closely related to dimensions, and a Factor Hierarchy to represent the underlying legal reasons (Aleven, 1997; Ashley & Aleven, 1997; Ashley, 2002). (For a description of the differences between dimensions and factors, see Rissland & Ashley (2002).) Since CATO provided legal reasons why shared factors favor a similar result or why distinctions are or are not legally significant, it could abstractly characterize cases and interpret them differently depending on the side for which it argues (Ashley & Aleven, 1997). In a controlled experiment, Aleven and Ashley demonstrated the effectiveness of CATO's case-based teaching strategies; CATO taught basic skills of case-based legal argument as effectively as an accomplished human instructor. Aleven also defined new ways for selecting the most relevant cases in terms of CATO's and HYPO's argumentation criteria and demonstrated their value in predicting case outcomes (Aleven, 2003). Ashley's student Stefanie Br\\xfcninghaus developed an alternative prediction approach, 'issue-based prediction' (IBP), that breaks problems into issues, generates hypotheses about which side should win each issue, tests the hypotheses by attempting to explain away counterexamples, and combines the issue-based predictions into an overall prediction and explanation (Br\\xfcninghaus & Ashley, 2003).\"], 'title': u'HYPO and its progeny'}, {'paragraphs': [u\"Several systems have addressed the problem of finding relevant information in cases and the corpus of highly interconnected legal knowledge. SPIRE, developed by Rissland and her student Jody Daniels, used information gleaned from a claim lattice to drive a standard full text retrieval engine to generate queries and then retrieve documents (case opinions) and highlight passages within them (Rissland & Daniels, 1996; Daniels & Rissland, 1997). Br\\xfcninghaus and Ashley developed SMILE, a system that employed learning techniques to extract information about factors from textually described cases using 'Propositional Patterns' (ProPs), a representation that captures information about actors, actions, and objects (Br\\xfcninghaus & Ashley, 2001, 2005). The combined SMILE and IBP programs analyzed textually described problems, predicted their outcomes, and explained the predictions. They demonstrated the utility of the ProP representation.\", u\"The goal of the BankXX system was to harvest balanced collections of information (e.g., on-point cases both for and against one's side, legal theories) to use in argument (Rissland et al., 1996).\"], 'title': u'CBR and legal information retrieval, gathering, and extraction'}, {'paragraphs': [u\"CABARET, a hybrid system, integrated HYPO-style CBR and classic rule-based reasoning (RBR) (Rissland & Skalak, 1991). A pioneer in multi-modal reasoning, CABARET used a dynamic agenda-based control architecture to interleave CBR and RBR so that these two reasoning modes could complement and supplement each other. CABARET produced memos outlining statutory arguments, including supporting and contrary cases, in a statutory area of United States tax law concerning home office deductions. CABARET's agenda was controlled by heuristic rules that embodied a theory of statutory interpretation, that is, a theory of how to argue about the meaning of legal rules and rule predicates, which often pose troublesome problems such as unstated exceptions and incurable open-texture. For instance, if all but one of a rule's prerequisites were satisfied (a rule-based 'near miss'), CABARET could use cases to argue that the predicate had actually been satisfied, or alternatively, that it was not a necessary condition. CABARET was a landmark system for CBR in that it was the first hybrid system to give equal status to both case-based reasoning and rule-based reasoning, and to allow them to interleave dynamically.\", u\"). As a project in AI and law, CABARET was important because it operationalized a three-tiered theory of interpretive statutory argument using 'argument strategies, moves, and primitives' (Skalak & Rissland, 1992). This theory can be viewed as part of an 'argumentation pyramid' whose base contains case facts, intermediate levels, dimensions and factors, statutory rules, court-made theories and tests, culminating in legal policies and principles. Computational models of case-based legal reasoning implement algorithms for navigating among the levels and bringing them to bear on analyzing and explaining problems (Ashley & Rissland, 2003).\", u\"The GREBE system pioneered the adaptation and reuse of case justifications for argument creation (Branting 1991, 2003). GREBE's model of argument structure includes both rule applications and exemplar-based explanations (EBEs) that relate portions of case facts to the conclusions they justify. This model of argument structure was the basis of a reduction-graph model of legal precedents later elaborated in Branting (1994, 2000). GREBE used a detailed relational representation of case facts and structure matching for similarity assessment. Like CABARET, GREBE is a hybrid CBR/RBR program that reasons with both rules and cases. For instance, it creates case analogies when the rules run out or otherwise fail to show that a legal term has been satisfied. GREBE used a heuristic measure of argument strength to rank the arguments for and against a given conclusion. Branting also tackled the issue of how to evaluate a CBR system that operates in a domain having nuanced answers. He used a domain expert to grade GREBE's analyses and those of law students in a blind test. The expert's evaluation of GREBE's analyses compared favorably with those of the law students. CBR research in law has created other hybrids. The IKBALS III program combined CBR with induced rules (Zeleznikow et al., 1994); it augmented induced rule-based explanations with case examples illustrating alternative conclusions. Later work on the Split-Up project combined CBR with structured connectionist networks to predict judicial allocations of marital property in divorce cases (Zeleznikow et al., 1996). CBR methodologies have also been extended to other legal tasks and to related domains. The CHIRON project explored the use of cases to guide tax planning. Precedents helped evaluate prototypical transaction plans and suggest possible plan adaptations (Sanders, 2001). The Truth-Teller and SIROCCO systems worked in the domain of ethics, a law-like normative system employing case-based techniques such as line drawing with prototypical examples. Truth-Teller took arbitrarily selected pairs of truth-telling dilemmas and explained how they were similar or different in a manner comparable to undergraduates' explanations (Ashley & McLaren, 1995). The SIROCCO program accepted engineering ethics problems and retrieved relevant past cases and ethical principles to help the user evaluate the new case (McLaren, 2003). By turning case knowledge on and off, SIROCCO empirically demonstrated the contribution past case decisions make in fleshing out the meaning of general normative principles.\", u'), Bench-Capon and Sartor have investigated reasoning about values and goals. They have studied how cases give rise to preference rules among competing values; new cases are decided so as to optimize consistency with value preferences (Bench-Capon & Sartor, 2003).'], 'title': u'Reasoning with legal cases and rules'}, {'paragraphs': [u\"Research on case-based approaches to law continues to make a vital contribution to CBR. Not only has it contributed to the birth of CBR and, in particular, interpretive CBR, but it has also spurred development of hybrid systems that combine case-based and other reasoning modes. It currently drives considerable work in the field of textual CBR. Its focus on comparing and contrasting cases in terms of the reasons why relevant similarities and differences are important has also been 'rediscovered' in the CBR field's recent focus on explanation-guided retrieval (Nugent et al., 2005).\"], 'title': u'Conclusion'}, {'paragraphs': [u\"Edwina Rissland's contribution to this material is based in part upon work supported as independent research while serving at the National Science Foundation. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.\"], 'title': u'Acknowledgements'}, {'paragraphs': [], 'title': u''}], 'properties': {'publisher': {'date': u'2006', 'publisher': u'Cambridge University Press', 'availability': u'Copyright Cambridge University Press\\n'}, 'journal': {'volume': u'203', 'publisher': u'Cambridge University Press', 'published': u'2006', 'page': {'to': '298', 'from': '293'}, 'title': u'The Knowledge Engineering Review'}, 'doi': u'10.1017/S0269888906000701', 'type': 'article', 'authors': [{'name': {'middle': u'D', 'first': u'E'}}, {'name': {'first': u'I'}}, {'affiliation': {'department': u'Department of Computer Science', 'institution': u'University of Massachusetts', 'address': {'country': u'USA', 'region': u'MA', 'settlement': u'Amherst', 'postcode': u'01003'}}, 'name': {'rolename': u'I S S', 'middle': u'L R', 'surname': u'L A N D', 'first': u'A'}}, {'name': {'rolename': u'K E V I N D. A S H', 'middle': u'E', 'first': u'L'}}, {'affiliation': {'department': u'Graduate Program in Intelligent Systems and School of Law', 'institution': u'University of Pittsburgh', 'address': {'country': u'USA', 'region': u'PA', 'settlement': u'Pittsburgh', 'postcode': u'15260'}}, 'name': {'surname': u'K A R L B R A N T', 'first': u'L'}}, {'name': {'middle': u'N', 'first': u'I'}}]}, 'title': u'Case-based reasoning and law'}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "filename = \"The Knowledge Engineering Review 2006 RISSLAND.tei.xml\"\n",
    "article = parse_file(filename)\n",
    "\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
